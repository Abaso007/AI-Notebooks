{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/81300/AI-Notebooks/blob/main/Colab-TextGen-GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM text generation notebook for Google Colab\n",
        "\n",
        "Version: GPU\n",
        "\n",
        "This notebook uses **oobabooga**'s [text-generation-webui project](https://github.com/oobabooga/text-generation-webui).\n",
        "\n",
        "Run all the cells and a public URL will appear at the bottom.\n",
        "\n",
        "## Useful links\n",
        "\n",
        "* [Web UI wiki](https://github.com/oobabooga/text-generation-webui/wiki)\n",
        "* [Hugging Face model hub](https://huggingface.co/models)\n",
        "* [Chatbot character creator](https://oobabooga.github.io/character-creator.html)\n",
        "\n",
        "## Credits\n",
        "\n",
        "* [oobabooga's notebook](https://github.com/oobabooga/AI-Notebooks)\n",
        "* [text-generation-webui](https://github.com/oobabooga/text-generation-webui)"
      ],
      "metadata": {
        "id": "MFQl6-FjSYtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Keep the tab alive { display-mode: \"form\" }\n",
        "\n",
        "#@markdown This can prevent Colab from terminating your runtime. Press play on the music player that will appear below:\n",
        "\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "f7TVVj_z4flw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Install the web UI\n",
        "\n",
        "Save_data_to_Google_Drive = False #@param {type:\"boolean\"}\n",
        "Install_GPTQ = True #@param {type:\"boolean\"}\n",
        "Reinstall_all = False #@param {type:\"boolean\"}\n",
        "\n",
        "if Save_data_to_Google_Drive:\n",
        "  import os\n",
        "  import shutil\n",
        "  from google.colab import drive\n",
        "  drive.mount(\"/content/drive\")\n",
        "  drive_folder = \"/content/drive/MyDrive\"\n",
        "\n",
        "if Reinstall_all:\n",
        "  !rm -r $repo_path\n",
        "\n",
        "import os\n",
        "repo_path = \"/content/Colab-TextGen\"\n",
        "if not os.path.exists(repo_path):\n",
        "  os.mkdir(repo_path)\n",
        "\n",
        "%cd $repo_path\n",
        "![[ ! -d .git ]] && git clone https://github.com/oobabooga/text-generation-webui .\n",
        "!git reset --hard\n",
        "!git pull\n",
        "!pip install --no-cache-dir --progress-bar=off -r requirements.txt\n",
        "!pip install --no-cache-dir --progress-bar=off -r extensions/api/requirements.txt\n",
        "!wget https://oobabooga.github.io/settings-colab.json -O settings-colab.json\n",
        "\n",
        "if Save_data_to_Google_Drive:\n",
        "  if not os.path.exists(f\"{drive_folder}/oobabooga-data\"):\n",
        "    os.mkdir(f\"{drive_folder}/oobabooga-data\")\n",
        "  if not os.path.exists(f\"{drive_folder}/oobabooga-data/logs\"):\n",
        "    os.mkdir(f\"{drive_folder}/oobabooga-data/logs\")\n",
        "  if not os.path.exists(f\"{drive_folder}/oobabooga-data/softprompts\"):\n",
        "    os.mkdir(f\"{drive_folder}/oobabooga-data/softprompts\")\n",
        "  if not os.path.exists(f\"{drive_folder}/oobabooga-data/characters\"):\n",
        "    shutil.move(f\"{repo_path}/characters\", f\"{drive_folder}/oobabooga-data/characters\")\n",
        "  else:\n",
        "    !rm -r \"$repo_path/characters\"\n",
        "    \n",
        "  !rm -r \"$repo_path/softprompts\"\n",
        "  !ln -sf \"$drive_folder/oobabooga-data/logs\" \"$repo_path/logs\"\n",
        "  !ln -sf \"$drive_folder/oobabooga-data/softprompts\" \"$repo_path/softprompts\"\n",
        "  !ln -sf \"$drive_folder/oobabooga-data/characters\" \"$repo_path/characters\"\n",
        "\n",
        "if Install_GPTQ:\n",
        "  !mkdir repositories\n",
        "  %cd repositories\n",
        "  !git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\n",
        "  %cd GPTQ-for-LLaMa\n",
        "  !python setup_cuda.py install"
      ],
      "metadata": {
        "id": "F1mssJmZ5BMg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Select a model\n",
        "\n",
        "HuggingFace_Organization = \"\" #@param {type:\"string\"}\n",
        "HuggingFace_Model = \"\" #@param {type:\"string\"}\n",
        "HuggingFace_Branch = \"main\" #@param [\"main\"] {allow-input: true}\n",
        "Redownload = False #@param {type: \"boolean\"}\n",
        "Delete_all_models = False #@param {type: \"boolean\"}\n",
        "\n",
        "repo_path = \"/content/Colab-TextGen\"\n",
        "models_path = \"/content/Colab-TextGen/models\"\n",
        "\n",
        "if HuggingFace_Branch != \"main\":\n",
        "  model_name = HuggingFace_Organization + \"_\" + HuggingFace_Model + \"_\" + HuggingFace_Branch\n",
        "else:\n",
        "  model_name = HuggingFace_Organization + \"_\" + HuggingFace_Model\n",
        "\n",
        "if Delete_all_models:\n",
        "  import os\n",
        "  if os.path.isdir(models_path):\n",
        "    %cd $models_path\n",
        "    !find . -mindepth 1 -maxdepth 1 -type d -exec rm -rv \"{}\" \\;\n",
        "  else:\n",
        "    print(\"Not a valid models directory.\")\n",
        "\n",
        "%cd $repo_path\n",
        "if Redownload:\n",
        "  !python download-model.py $HuggingFace_Organization/$HuggingFace_Model --branch $HuggingFace_Branch --clean\n",
        "else:\n",
        "  !python download-model.py $HuggingFace_Organization/$HuggingFace_Model --branch $HuggingFace_Branch"
      ],
      "metadata": {
        "id": "yyl9TGSoRIwV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Launch\n",
        "\n",
        "Mode = \"Notebook\" #@param [\"Notebook\", \"Chat\", \"API\"] {allow-input: false}\n",
        "Extra_launch_arguments = None #@param [\"--load-in-8bit\", \"--wbits 4 --model_type llama --groupsize 128\", \"--wbits 4 --model_type llama --groupsize 32\"] {allow-input: true}\n",
        "\n",
        "if Extra_launch_arguments is None:\n",
        "  Extra_launch_arguments = \"\"\n",
        "\n",
        "%cd $repo_path\n",
        "if Mode == \"Notebook\":\n",
        "  !python server.py --share --model $model_name --settings settings-colab.json --notebook $Extra_launch_arguments\n",
        "elif Mode == \"Chat\":\n",
        "  !python server.py --share --model $model_name --settings settings-colab.json --chat $Extra_launch_arguments\n",
        "elif Mode == \"API\":\n",
        "  !python server.py --share --model $model_name --extensions api $Extra_launch_arguments\n",
        "else:\n",
        "  print(\"No valid mode selected.\")"
      ],
      "metadata": {
        "id": "txeAxCGyRK1F",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}